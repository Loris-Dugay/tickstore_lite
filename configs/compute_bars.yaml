spark:
  format: "delta"
  mode: "append"
  partitions:
  max_records_per_file:
  partition_overwrite_mode: "dynamic"
paths:
  input: "data/transformed/"
  output: "data/bars/"
repartition_cols:
  - "symbol"
  - "bucket"
sort_cols:
  - "symbol"
  - "open_time"
columns:
  timestamp: "ts"
fill_missing: true
filters:
  symbols: []
  start_date:
  end_date:
